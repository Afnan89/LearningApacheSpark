{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reference: \n",
    "# http://stackoverflow.com/questions/42889965/multiply-two-numpy-matrices-in-pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark Matrix multiplication with python example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simple demo for small dense matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg.distributed import *\n",
    "\n",
    "def as_block_matrix(rdd, rowsPerBlock=2, colsPerBlock=3):\n",
    "    return IndexedRowMatrix(\n",
    "        rdd.zipWithIndex().map(lambda xi: IndexedRow(xi[1], xi[0]))\n",
    "    ).toBlockMatrix(rowsPerBlock, colsPerBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A =  np.array([1,1,3,4,5,3],dtype=np.float64).reshape(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  3.],\n",
       "       [ 4.,  5.,  3.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrixA = as_block_matrix(spark.sparkContext.parallelize(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tA = matrixA.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(3, 2, [1.0, 1.0, 3.0, 4.0, 5.0, 3.0], 0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tA.toLocalMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mul = matrixA.multiply(tA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(2, 2, [11.0, 18.0, 18.0, 50.0], 0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul.toLocalMatrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Simple demo for small dense matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from numpy import array\n",
    "I = array([0,3,1,0])\n",
    "J = array([0,3,1,2])\n",
    "V = array([4,5,7,9])\n",
    "A = sparse.coo_matrix((V,(I,J)),shape=(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dA = A.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg.distributed import *\n",
    "\n",
    "def as_block_matrix(rdd, rowsPerBlock=4, colsPerBlock=4):\n",
    "    return IndexedRowMatrix(\n",
    "        rdd.zipWithIndex().map(lambda xi: IndexedRow(xi[1], xi[0]))\n",
    "    ).toBlockMatrix(rowsPerBlock, colsPerBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrixA = as_block_matrix(spark.sparkContext.parallelize(dA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Demo for large matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "A = np.arange(1024 ** 2, dtype=np.float32).reshape(1024, 1024)\n",
    "B = np.arange(1024 ** 2, dtype=np.float32).reshape(1024, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   1.00000000e+00,   2.00000000e+00, ...,\n",
       "          1.02100000e+03,   1.02200000e+03,   1.02300000e+03],\n",
       "       [  1.02400000e+03,   1.02500000e+03,   1.02600000e+03, ...,\n",
       "          2.04500000e+03,   2.04600000e+03,   2.04700000e+03],\n",
       "       [  2.04800000e+03,   2.04900000e+03,   2.05000000e+03, ...,\n",
       "          3.06900000e+03,   3.07000000e+03,   3.07100000e+03],\n",
       "       ..., \n",
       "       [  1.04550400e+06,   1.04550500e+06,   1.04550600e+06, ...,\n",
       "          1.04652500e+06,   1.04652600e+06,   1.04652700e+06],\n",
       "       [  1.04652800e+06,   1.04652900e+06,   1.04653000e+06, ...,\n",
       "          1.04754900e+06,   1.04755000e+06,   1.04755100e+06],\n",
       "       [  1.04755200e+06,   1.04755300e+06,   1.04755400e+06, ...,\n",
       "          1.04857300e+06,   1.04857400e+06,   1.04857500e+06]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg.distributed import *\n",
    "\n",
    "def as_block_matrix(rdd, rowsPerBlock=1024, colsPerBlock=1024):\n",
    "    return IndexedRowMatrix(\n",
    "        rdd.zipWithIndex().map(lambda xi: IndexedRow(xi[1], xi[0]))\n",
    "    ).toBlockMatrix(rowsPerBlock, colsPerBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.8 ms, sys: 12.9 ms, total: 49.6 ms\n",
      "Wall time: 1.09 s\n",
      "CPU times: user 30.6 ms, sys: 8.93 ms, total: 39.5 ms\n",
      "Wall time: 980 ms\n"
     ]
    }
   ],
   "source": [
    "%time matrixA = as_block_matrix(spark.sparkContext.parallelize(A))\n",
    "%time matrixB = as_block_matrix(spark.sparkContext.parallelize(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.21 s, sys: 64.8 ms, total: 1.28 s\n",
      "Wall time: 5.51 s\n"
     ]
    }
   ],
   "source": [
    "%time aaa= matrixA.toLocalMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.47 ms, sys: 1.62 ms, total: 4.09 ms\n",
      "Wall time: 6.86 s\n"
     ]
    }
   ],
   "source": [
    "%time product = matrixA.multiply(matrixB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.21 s, sys: 67 ms, total: 1.28 s\n",
      "Wall time: 6.24 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DenseMatrix(1024, 1024, [365967179776.0, 915186122752.0, 1.4644, 2.0136, 2.5628, 3.1120, 3.6612, 4.2104, ..., 5.5946, 5.6001, 5.6056, 5.6111, 5.6166, 5.6221, 5.6276, 5.6331], 0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time product.toLocalMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
